syntax = "proto3";

package scheduler.scheduler_proto;
option go_package = "github.com/mennanov/scalemate/scheduler/scheduler_proto";

import "google/protobuf/empty.proto";
import "google/protobuf/timestamp.proto";

import "shared/proto/validator.proto";

service Scheduler {
    // GetNode gets the Node details.
    rpc GetNode(NodeLookupRequest) returns (Node){
    }
    // ListNodes lists Nodes that satisfy the given criteria.
    rpc ListNodes(ListNodesRequest) returns (ListNodesResponse){
    }

    // CreateJob creates a new Job.
    rpc CreateJob (Job) returns (Job) {
    }
    // GetJob gets a User owned Job.
    rpc GetJob (JobLookupRequest) returns (Job) {
    }
    // ListJobs lists User owned Jobs.
    rpc ListJobs (ListJobsRequest) returns (ListJobsResponse) {
    }
    // CancelJob cancels an already created Job. The corresponding running Tasks will also be cancelled.
    rpc CancelJob (JobLookupRequest) returns (Job) {
    }

    // GetTask gets a User owned Task.
    rpc GetTask (TaskLookupRequest) returns (Task) {
    }
    // ListTasks lists User owned Tasks.
    rpc ListTasks (ListTasksRequest) returns (ListTasksResponse) {
    }
    // IterateTasks sends a stream of all the Tasks for the given Job.
    // A new Task is created when a Job is scheduled on a certain Node.
    rpc IterateTasks (IterateTasksRequest) returns (stream Task) {
    }
    // IterateTasksForNode should be used by Nodes to receive Tasks to run. A Node is considered online as long as this
    // RPC is in progress, otherwise it is considered offline.
    rpc IterateTasksForNode (google.protobuf.Empty) returns (stream Task) {
    }
    // CancelTask cancels a running Task. It also notifies the corresponding Node to stop the Task.
    rpc CancelTask (TaskLookupRequest) returns (Task){
    }

    // ListCpuModels lists aggregated CPU models for the currently online Nodes.
    rpc ListCpuModels (ListCpuModelsRequest) returns (ListCpuModelsResponse) {
    }
    // ListGpuModels lists aggregated GPU models for the currently online Nodes.
    rpc ListGpuModels (ListGpuModelsRequest) returns (ListGpuModelsResponse) {
    }
    // ListDiskModels lists aggregated Disk models for the currently online Nodes.
    rpc ListDiskModels (ListDiskModelsRequest) returns (ListDiskModelsResponse) {
    }
    // ListMemoryModels lists aggregated Memory models for the currently online Nodes.
    rpc ListMemoryModels (google.protobuf.Empty) returns (ListMemoryModelsResponse) {
    }
}

enum CPUClass {
    CPU_CLASS_UNKNOWN = 0;
    CPU_CLASS_ENTRY = 10;
    CPU_CLASS_INTERMEDIATE = 20;
    CPU_CLASS_ADVANCED = 30;
    CPU_CLASS_PRO = 40;
}

enum GPUClass {
    GPU_CLASS_UNKNOWN = 0;
    GPU_CLASS_ENTRY = 10;
    GPU_CLASS_INTERMEDIATE = 20;
    GPU_CLASS_ADVANCED = 30;
    GPU_CLASS_PRO = 40;
}

enum DiskClass {
    DISK_CLASS_UNKNOWN = 0;
    DISK_CLASS_HDD = 10;
    DISK_CLASS_SSD = 20;
}

// Job represents a request to be run as a container on Scalemate premises.
// This is created by `scalemate run image:tag [OPTIONS]`.
message Job {
    // Readonly.
    uint64 id = 1 [(shared.proto.validator.field) = {int_lt: 1}];
    string username = 2 [(shared.proto.validator.field) = {regex: "^(([a-z0-9_]{3,32})|)$"}];

    enum Status {
        // Default status value.
        STATUS_NEW = 0;
        // The Job is declined (due to insufficient funds, etc.).
        STATUS_DECLINED = 1;
        // When a new Job is created it has the status PENDING. Which means it is waiting to be scheduled.
        STATUS_PENDING = 2;
        // The Job is scheduled (assigned) to a Node. After that the more granular info about the status should be
        // retrieved from a corresponding Task.
        STATUS_SCHEDULED = 3;
        // The Job has finished and does not need to be rescheduled.
        STATUS_FINISHED = 4;
        // The Job was manually cancelled by a user.
        STATUS_CANCELLED = 5;
    }
    // Readonly.
    Status status = 14 [(shared.proto.validator.field) = {int_lt: 1}];

    message RunConfig {
        // Docker image name, e.g. "postgres:latest".
        string image = 1 [(shared.proto.validator.field) = {msg_exists: true, length_gt: 1}];
        // Docker optional command with an arguments string, e.g. "bash -c 'echo hi'".
        string command = 2;
        // Exposed ports as a map <local port, remote container port>.
        map<uint32, uint32> ports = 3;
        // Docker volumes as a map <host path relative to the working dir, container absolute path>,
        // e.g. "./postgres_data:/var/lib/postgresql".
        map<string, string> volumes = 4;
        // Paths to be downloaded from a Node after the Job is finished as a map
        // <path relative to the working dir on a remote Node, local path>, e.g. "./postgres_data:/tmp/pg_data".
        map<string, string> download_paths = 5;
        // Exclude these remote paths from being downloaded.
        repeated string download_paths_exclude = 6;
        // Paths to be uploaded to a remote Node before container is started as a map
        // <local path, path relative to the working dir on a remote Node>, e.g. "./:./".
        map<string, string> upload_paths = 7;
        // Exclude these local paths from being uploaded to a remote Node.
        repeated string upload_paths_exclude = 8;
        // Docker container environment variables.
        map<string, string> environment_variables = 9;
        // Overwrite the default ENTRYPOINT of the image.
        string entrypoint = 10;
    }
    // Docker specific parameters like image name, ports, volumes, etc.
    RunConfig run_config = 3 [(shared.proto.validator.field) = {msg_exists: true}];

    // Docker run CPU limits. See https://docs.docker.com/config/containers/resource_constraints/
    float cpu_limit = 4 [(shared.proto.validator.field) = {float_gte: 0.01, float_epsilon: 0.01}];
    CPUClass cpu_class = 5;

    // Docker run Memory limit in Megabytes.
    uint32 memory_limit = 6 [(shared.proto.validator.field) = {int_gt: 0}];

    // The number of GPU devices to be used. Limiting the number of cores in a single device is not supported.
    uint32 gpu_limit = 7;
    GPUClass gpu_class = 8;

    // Disk limit in Megabytes. This includes the image size, writable container layer and volumes.
    uint32 disk_limit = 9 [(shared.proto.validator.field) = {int_gt: 0}];
    DiskClass disk_class = 10;

    // Readonly.
    google.protobuf.Timestamp created_at = 12;
    // Readonly.
    google.protobuf.Timestamp updated_at = 13;

    enum RestartPolicy {
        RESTART_POLICY_NO = 0;
        RESTART_POLICY_ON_FAILURE = 1;
        RESTART_POLICY_UNLESS_STOPPED = 2;
        RESTART_POLICY_RESCHEDULE_ON_FAILURE = 3;
        RESTART_POLICY_RESCHEDULE_ON_NODE_FAILURE = 4;
    }

    RestartPolicy restart_policy = 15;

    // Scheduling constraint labels. Multiple labels with the same prefix are "OR"ed.
    // Only the full string match is currently supported.
    repeated string cpu_labels = 16;
    repeated string gpu_labels = 17;
    repeated string disk_labels = 18;
    repeated string memory_labels = 19;
    repeated string username_labels = 20;
    repeated string name_labels = 21;
    repeated string other_labels = 22;

    // Indicates that the Job is a daemon. If so, then a Node to which a corresponding Task was scheduled will not wait
    // for an established p2p connection with client and will run a container immediately.
    bool is_daemon = 23;
}

// Node represents a physical machine (computer) that is used to run Tasks.
message Node {
    uint64 id = 1;
    string username = 2 [(shared.proto.validator.field) = {regex: "^(([a-z0-9_]{3,32})|)$"}];
    string name = 24 [(shared.proto.validator.field) = {regex: "^(([a-z0-9_]{3,32})|)$"}];

    enum Status {
        // Node is offline and is not able to run Jobs.
        STATUS_OFFLINE = 0;
        // Indicates that the Node is online and ready to run Jobs.
        STATUS_ONLINE = 1;
        // Node is gracefully shutting down: it's waiting for all the Tasks to complete and is not accepting new Tasks.
        STATUS_SHUTTING_DOWN = 2;
    }
    Status status = 3;

    // The number of CPUs the node has.
    uint32 cpu_capacity = 4 [(shared.proto.validator.field) = {int_gt: 0}];
    // The number of CPUs available for scheduling.
    float cpu_available = 5 [(shared.proto.validator.field) = {float_gte: 0}];
    CPUClass cpu_class = 6 [(shared.proto.validator.field) = {msg_exists: true}];
    // The lowest requested Job's CPUClass that can be scheduled on that Node.
    CPUClass cpu_class_min = 7 [(shared.proto.validator.field) = {msg_exists: true}];
    string cpu_model = 20 [(shared.proto.validator.field) = {msg_exists: true}];

    // Node's RAM capacity in Megabytes available for Jobs scheduling.
    uint32 memory_capacity = 8 [(shared.proto.validator.field) = {int_gt: 0}];
    // Node's RAM in Megabytes available for scheduling.
    uint32 memory_available = 9 [(shared.proto.validator.field) = {int_gt: 0}];
    string memory_model = 25 [(shared.proto.validator.field) = {msg_exists: true}];

    // The number of GPU devices the node has.
    uint32 gpu_capacity = 10;
    // The number of GPU devices available for scheduling.
    uint32 gpu_available = 11;
    GPUClass gpu_class = 12 [(shared.proto.validator.field) = {msg_exists: true}];
    // The lowest requested Job's GPUClass that can be scheduled on that Node.
    GPUClass gpu_class_min = 13 [(shared.proto.validator.field) = {msg_exists: true}];
    string gpu_model = 26 [(shared.proto.validator.field) = {msg_exists: true}];

    // Node's disk capacity in Megabytes available for Jobs scheduling.
    uint32 disk_capacity = 14;
    // Node's disk in Megabytes available for Jobs scheduling.
    uint32 disk_available = 15;
    DiskClass disk_class = 16 [(shared.proto.validator.field) = {msg_exists: true}];
    // The lowest requested Jobs's DiskClass that can be scheduled on that Node.
    DiskClass disk_class_min = 17 [(shared.proto.validator.field) = {msg_exists: true}];
    string disk_model = 27 [(shared.proto.validator.field) = {msg_exists: true}];

    // User defined labels.
    repeated string labels = 29;

    // Number of all finished Tasks that this Node has run.
    uint64 tasks_finished = 30;
    // Number of Tasks that failed on this Node when the Node was at fault. Used to calculate reliability score.
    uint64 tasks_failed = 31;

    // The most recent connection time.
    google.protobuf.Timestamp connected_at = 18;
    // The most recent disconnect time.
    google.protobuf.Timestamp disconnected_at = 19;
    // The most recent time a Task was scheduled on this Node.
    google.protobuf.Timestamp scheduled_at = 21;

    // Time this Node was initially registered.
    google.protobuf.Timestamp created_at = 22;
    google.protobuf.Timestamp updated_at = 23;
}

message NodeLookupRequest {
    uint64 node_id = 1 [(shared.proto.validator.field) = {int_gt: 0}];
}

message ListNodesRequest {
    string username = 1 [(shared.proto.validator.field) = {regex: "^([a-z0-9_]{3,32})?$"}];
    repeated Node.Status status = 2;

    enum Ordering {
        CONNECTED_AT_DESC = 0;
        CONNECTED_AT_ASC = 1;
        DISCONNECTED_AT_DESC = 2;
        DISCONNECTED_AT_ASC = 3;
        SCHEDULED_AT_DESC = 4;
        SCHEDULED_AT_ASC = 5;
    }
    // CONNECTED_AT_DESC is used by default.
    Ordering ordering = 3;

    // Limit of 50 is used by default.
    uint32 limit = 4 [(shared.proto.validator.field) = {int_lt: 1000}];
    uint32 offset = 5;

    // Matches Nodes with cpu_available >= given value.
    float cpu_available = 6 [(shared.proto.validator.field) = {float_gte: 0}];
    // Matches Nodes with cpu_class_min <= given value <= cpu_class.
    CPUClass cpu_class = 7;

    // Matches Nodes with memory_available >= given value.
    uint32 memory_available = 8 [(shared.proto.validator.field) = {int_gt: 0}];

    // Matches Nodes with gpu_available >= given value.
    uint32 gpu_available = 9;
    // Matches Nodes with gpu_class_min <= given value <= gpu_class.
    GPUClass gpu_class = 10;

    // Matches Nodes with disk_available >= given value.
    uint32 disk_available = 11;
    // Matches Nodes with disk_class_min <= given value <= disk_class.
    DiskClass disk_class = 12;

    // Matches Nodes with similar labels (non-empty intersection).
    repeated string labels = 13;
    // Matches Nodes with tasks_finished >= given value.
    uint64 tasks_finished = 14;
    // Matches Nodes with tasks_failed <= given value.
    uint64 tasks_failed = 15;
}

message ListNodesResponse {
    repeated Node nodes = 1;
    // Total count of Nodes that match the corresponding ListNodesRequest without limit or offset applied.
    uint32 total_count = 2;
}

// Task represents a scheduled (running) Job on a Node.
message Task {
    uint64 id = 1;
    uint64 job_id = 2;
    uint64 node_id = 3;

    enum Status {
        STATUS_NEW = 0;
        // Downloading a Docker image and user context, running container, uploading context.
        STATUS_RUNNING = 1;
        // Container finished execution regardless of the result (container exit code: failure or success).
        STATUS_FINISHED = 2;
        // Any non-node related failure: image not found, resources exhausted, container failed, etc.
        STATUS_FAILED = 3;
        // Task failed because the Node failed: connection failed, power outage, etc.
        STATUS_NODE_FAILED = 4;
        // Task is cancelled manually by the user.
        STATUS_CANCELLED = 5;
    }
    Status status = 4;

    google.protobuf.Timestamp created_at = 5;
    google.protobuf.Timestamp updated_at = 6;

    // The time when the container started to run.
    google.protobuf.Timestamp started_at = 7;

    // The time when the container finished to run (for any reason).
    google.protobuf.Timestamp finished_at = 8;
}

message JobLookupRequest {
    uint64 job_id = 1 [(shared.proto.validator.field) = {int_gt: 0}];
}

message ListJobsRequest {
    string username = 1 [(shared.proto.validator.field) = {regex: "^([a-z0-9_]{3,32})$"}];
    repeated Job.Status status = 2;

    enum Ordering {
        CREATED_AT_DESC = 0;
        CREATED_AT_ASC = 1;
        UPDATED_AT_DESC = 2;
        UPDATED_AT_ASC = 3;
    }
    // CREATED_AT_DESC is used by default.
    Ordering ordering = 3;

    // Limit of 50 is used by default.
    uint32 limit = 4 [(shared.proto.validator.field) = {int_lt: 1000}];
    uint32 offset = 5;
}

message ListJobsResponse {
    repeated Job jobs = 1;
    // Total count of Jobs that match the corresponding ListJobsRequest without limit or offset applied.
    uint32 total_count = 2;
}

message TaskLookupRequest {
    uint64 task_id = 1 [(shared.proto.validator.field) = {int_gt: 0}];
}

message ListTasksRequest {
    // Username must be equal to the currently logged-in user's username (for non-admin users).
    string username = 1 [(shared.proto.validator.field) = {regex: "^([a-z0-9_]{3,32})$"}];
    repeated uint64 job_id = 2;
    repeated Task.Status status = 3;

    enum Ordering {
        CREATED_AT_DESC = 0;
        CREATED_AT_ASC = 1;
        UPDATED_AT_DESC = 2;
        UPDATED_AT_ASC = 3;
    }
    // CREATED_AT_DESC is used by default.
    Ordering ordering = 4;

    // Limit of 50 is used by default.
    uint32 limit = 5 [(shared.proto.validator.field) = {int_lt: 1000}];
    uint32 offset = 6;
}

message IterateTasksRequest {
    uint64 job_id = 1;
    bool include_existing = 2;
}

message ListTasksResponse {
    repeated Task tasks = 1;
    // Total count of Jobs that match the corresponding ListTasksRequest without limit or offset applied.
    uint32 total_count = 2;
}

message ListCpuModelsRequest {
    CPUClass cpu_class = 1;
}

message ListCpuModelsResponse {
    message CpuModel {
        string cpu_model = 1;
        CPUClass cpu_class = 2;
        // Total amount of all CPUs of that model.
        uint32 cpu_capacity = 3;
        // Total currently available CPUs of that model.
        float cpu_available = 4;
        // Total number of unique Nodes with that CPU model.
        uint32 nodes_count = 5;
    }
    repeated CpuModel cpu_models = 1;
}

message ListGpuModelsRequest {
    GPUClass gpu_class = 1;
}

message ListGpuModelsResponse {
    message GpuModel {
        string gpu_model = 1;
        GPUClass gpu_class = 2;
        // Total amount of all GPUs of that model.
        uint32 gpu_capacity = 3;
        // Total currently available GPUs of that model.
        uint32 gpu_available = 4;
        // Total number of unique Nodes with that GPU model.
        uint32 nodes_count = 5;
    }
    repeated GpuModel gpu_models = 1;
}

message ListDiskModelsRequest {
    DiskClass disk_class = 1;
}

message ListDiskModelsResponse {
    message DiskModel {
        string Disk_model = 1;
        DiskClass disk_class = 2;
        // Total amount of storage of that disk model in Megabytes.
        uint32 disk_capacity = 3;
        // Total currently available storage of that disk model in Megabytes.
        uint32 disk_available = 4;
        // Total number of unique Nodes with that disk model.
        uint32 nodes_count = 5;
    }
    repeated DiskModel disk_models = 1;
}

message ListMemoryModelsResponse {
    message MemoryModel {
        string memory_model = 1;
        // Total amount of memory of that model in Megabytes.
        uint32 memory_capacity = 2;
        // Total currently available memory of that model in Megabytes.
        uint32 memory_available = 3;
        // Total number of unique Nodes with that memory model.
        uint32 nodes_count = 4;
    }
    repeated MemoryModel memory_models = 1;
}
